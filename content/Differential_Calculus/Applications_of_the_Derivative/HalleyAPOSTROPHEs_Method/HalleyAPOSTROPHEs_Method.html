<div class="latex_section">
	Derivation
</div>
<div class="latex_body">
	We already know Newton's Method as:
	<div class="latex_equation">
		$\eqalign{
			x_{n + 1} = x_n - \frac{f(x_n)}{f'(x_n)}
		}$
	</div>
	In order to arrive at $\textit{Halley's Method}$ we define a new function:
	<div class="latex_equation">
		$\eqalign{
			g(x) = \frac{f(x)}{\sqrt{|f'(x)|}}
		}$
	</div>
	where any root of $f$ and not of $f'$ is a root of $g$ and any root of $g$ is a root of $f$. Next we will need the derivative which can be obtained easily when ignoring the absolute value and assuming the derivative is positive:: 
	<div class="latex_equation">
		$\eqalign{
			g'(x) &= \frac{d}{dx} \frac{f(x)}{\sqrt{f'(x)}} \\
			&= \frac{f'(x)\sqrt{f'(x)} - \frac{1}{2}f(x)f''(x)\sqrt{f'(x)}}{f'(x)} \\
			&= \frac{2(f'(x))^2 - f(x)f''(x)}{2f'(x)\sqrt{f'(x)}} \\
			&= \frac{2(f'(x))^2 - f(x)f''(x)}{2f'(x)\sqrt{|f'(x)|}}
		}$
	</div>
	where the absolute value is plugged back in on the last line to ensure the existence of the derivative. Plugging into Newton's Method provides:
	<div class="latex_equation">
		$\eqalign{
			x_{n + 1} &= x_n - \frac{g(x_n)}{g'(x_n)} \\
			&= x_n - \frac{f(x_n)}{\sqrt{|f'(x_n)|}} \cdot \frac{2f'(x_n)\sqrt{|f'(x_n)|}}{2(f'(x_n))^2 - f(x_n)f''(x_n)} \\
			&= x_n - \frac{2f(x_n)f'(x_n)}{2(f'(x_n))^2 - f(x_n)f''(x_n)}
		}$
	</div>
</div>

<div class="latex_section">
	Convergence
</div>
<div class="latex_body">
	Let us assume that we are trying to determine the root $x$ s.t. $f(x) = 0$, then the sequence of errors is defined as:
	<div class="latex_equation">
		$\eqalign{
			\epsilon_n = x - x_n
		}$
	</div>
	If the errors approach zero for larger values of $n$, then the algorithm converges to our final solution $x$. To begin I must first introduce a higher order approximation to the function. If we assume that our function can take the form:
	<div class="latex_equation">
		$\eqalign{
			f(x) = a_0 + a_1(x - x_0) + a_2(x - x_0)^2 + a_3(x - x_0)^3
		}$
	</div>
	then by differentiation:
	<div class="latex_equation">
		$\eqalign{
			f'(x) &= a_1 + 2a_2(x - x_0) + 3a_3(x - x_0)^2 \\
			f''(x) &= 2a_2 + 6a_3(x - x_0) \\
			f'''(x) &= 6a_3
		}$
	</div>
	and evaluation at $x = x_0$ we determine that the coefficients have to be:
	<div class="latex_equation">
		$\eqalign{
			a_0 &= f(x_0) \\
			a_1 &= f'(x_0) \\
			a_2 &= \frac{f''(x_0)}{2} \\
			a_3 &= \frac{f'''(x_0)}{6}
		}$
	</div>
	which is nothing more than an extension of the quadratic approximation, specifically known as a $\textit{cubic approximation}$. So we have:
	<div class="latex_equation">
		$\eqalign{
			f(x) &= f(x_0) + f'(x_0)(x - x_0) + \frac{f''(x_0)}{2}(x - x_0)^2 \\
			& \hspace{.4cm} + \frac{f'''(x_0)}{6}(x - x_0)^3
		}$
	</div>
	where we assume that the first, second, and third derivatives are continuous. So at $x_n$:
	<div class="latex_equation">
		$\eqalign{
			f(x) &= f(x_n) + f'(x_n)(x - x_n) + \frac{f''(x_n)}{2}(x - x_n)^2 \\
			& \hspace{.4cm} + \frac{f'''(x_n)}{6}(x - x_n)^3
		}$
	</div>
	Now multiplying the cubic approximation by $2f'(x_n)$:
	<div class="latex_equation">
		$\eqalign{
			f(x) &= 2f(x_n)f'(x_n) + 2[f'(x_n)]^2(x - x_n) \\
			& \hspace{.4cm} + f'(x_n)f''(x_n)(x - x_n)^2 \\
			& \hspace{.4cm} + \frac{f'(x_n)f'''(x_n)}{3}(x - x_n)^3
		}$
	</div>
	and the quadratic approximation by $f''(x_n)(x - x_n)$:
	<div class="latex_equation">
		$\eqalign{
			f(x) &= f(x_n)f''(x_n)(x - x_n) + f'(x_n)f''(x_n)(x - x_n)^2 \\
			& \hspace{.4cm} + \frac{(f''(x_n))^2}{2}(x - x_n)^3
		}$
	</div>
	gives us the tools needed. Subtracting the first equation from the second one right above results in:
	<div class="latex_equation">
		$\eqalign{
			0 &= -2f(x_n)f'(x_n) + \Big[ f(x_n)f''(x_n) \\
			& \hspace{.4cm} - 2(f'(x_n))^2 \Big](x - x_n) \\
			& \hspace{.4cm} + \Big[ \frac{(f''(x_n))^2}{2} - \frac{f'(x_n)f'''(x_n)}{3} \Big](x - x_n)^3 \\
			0 &= -\frac{2f(x_n)f'(x_n)}{f(x_n)f''(x_n) - 2(f'(x_n))^2} + (x - x_n) \\
			& \hspace{.4cm} + \frac{3(f''(x_n))^2 - 2f'(x_n)f'''(x_n)}{6(f(x_n)f''(x_n) - 2(f'(x_n))^2)}(x - x_n)^3 \\
			x - x_n &= -\frac{2f(x_n)f'(x_n)}{2(f'(x_n))^2 - f(x_n)f''(x_n)} \\
			& \hspace{.4cm} - \frac{2f'(x_n)f'''(x_n) - 3(f''(x_n))^2}{6(2(f'(x_n))^2 - f(x_n)f''(x_n))}(x - x_n)^3 \\
			x - x_n &= (x_{n + 1} - x_{n}) \\
			& \hspace{.4cm} - \frac{2f'(x_n)f'''(x_n) - 3(f''(x_n))^2}{12(f'(x_n))^2 - 6f(x_n)f''(x_n)}(x - x_n)^3 \\
			x - x_{n + 1} &= -\frac{2f'(x_n)f'''(x_n) - 3(f''(x_n))^2}{12(f'(x_n))^2 - 6f(x_n)f''(x_n)}(x - x_n)^3 \\
			\epsilon_{n + 1} &= -\frac{2f'(x_n)f'''(x_n) - 3(f''(x_n))^2}{12(f'(x_n))^2 - 6f(x_n)f''(x_n)}\epsilon_n^3 \\
			|\epsilon_{n + 1}| &= \Bigg| \frac{2f'(x_n)f'''(x_n) - 3(f''(x_n))^2}{12(f'(x_n))^2 - 6f(x_n)f''(x_n)} \Bigg| |\epsilon_n|^3 \\
		}$
	</div>
	The last line is the one that shows the rate of convergence is cubic due to the right side. We can even go on to show explicitly that the sequence of errors is decreasing by determining an upper bound, $\Omega \in \mathbb{R}$, s.t.:
	<div class="latex_equation">
		$\eqalign{
			|\epsilon_{n + 1}| \leq \Omega |\epsilon_n|^3
		}$
	</div>
	To define the upper bound we can use our conclusion from above and choose the maximal value that the ratio takes on our domain:
	<div class="latex_equation">
		$\eqalign{
			\Omega = \sup_x \Bigg| \frac{2f'(x)f'''(x) - 3(f''(x))^2}{12(f'(x))^2 - 6f(x)f''(x)} \Bigg|
		}$
	</div>
</div>